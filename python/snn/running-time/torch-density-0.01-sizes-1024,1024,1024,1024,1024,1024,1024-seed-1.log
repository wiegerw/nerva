=== Command line arguments ===
Namespace(debug=False, batch_size=100, seed=1, precision=4, edgeitems=3, density=0.01, sizes='3072,1024,1024,1024,1024,1024,1024,1024,10', epochs=1, lr=0.1, momentum=0.9, gamma=0.1, nesterov=True, datadir='./data', augmented=False, preprocessed=None, copy=False, nerva=False, torch=True, scheduler='multistep', export_weights_npz=None, import_weights_npz=None, custom_masking=True)
Setting gamma to 1.0
Files already downloaded and verified
initialize by ER
Overall sparsity 0.009999999999999998
Total Model parameters: 9447424
Total parameters under sparsity level of 0.01: 0.009994576299317147
initialize by ER
Overall sparsity 0.009999999999999998
Total Model parameters: 18894848
Total parameters under sparsity level of 0.01: 0.00041820923883589855
Use MLP1 variant with custom masking
Setting masks with densities [0.007062425842997664, 0.010593638764496496, 0.010593638764496496, 0.010593638764496496, 0.010593638764496496, 0.010593638764496496, 0.010593638764496496, 0.5476911241244689]
--- masks ---
mask1 (1024x3072)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask2 (1024x1024)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 1, 0,  ..., 1, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask3 (1024x1024)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask4 (1024x1024)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask5 (1024x1024)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask6 (1024x1024)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask7 (1024x1024)
tensor([[0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 0, 0],
        ...,
        [0, 0, 0,  ..., 0, 0, 0],
        [0, 0, 0,  ..., 0, 1, 0],
        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)
mask8 (10x1024)
tensor([[1, 0, 0,  ..., 1, 0, 0],
        [1, 1, 1,  ..., 1, 0, 0],
        [1, 0, 0,  ..., 0, 1, 1],
        ...,
        [1, 1, 0,  ..., 0, 0, 1],
        [1, 1, 1,  ..., 0, 1, 0],
        [0, 1, 0,  ..., 1, 1, 0]], dtype=torch.int32)

=== PyTorch model ===
MLP1a(
  (layers): ModuleList(
    (0): Linear(in_features=3072, out_features=1024, bias=True)
    (1): Linear(in_features=1024, out_features=1024, bias=True)
    (2): Linear(in_features=1024, out_features=1024, bias=True)
    (3): Linear(in_features=1024, out_features=1024, bias=True)
    (4): Linear(in_features=1024, out_features=1024, bias=True)
    (5): Linear(in_features=1024, out_features=1024, bias=True)
    (6): Linear(in_features=1024, out_features=1024, bias=True)
    (7): Linear(in_features=1024, out_features=10, bias=True)
  )
  (loss): CrossEntropyLoss()
)
CrossEntropyLoss()
<torch.optim.lr_scheduler.MultiStepLR object at 0x7f8b2d3a8d60>

=== Training PyTorch model ===
epoch   0  lr: 0.10000000  loss: 2.30278683  train accuracy: 0.10000000  test accuracy: 0.10000000  time: 0.00000000s
epoch   1  lr: 0.10000000  loss: 2.30514526  train accuracy: 0.10000000  test accuracy: 0.10000000  time: 32.77645526s
Accuracy of the network on the 10000 test images: 10.000 %
