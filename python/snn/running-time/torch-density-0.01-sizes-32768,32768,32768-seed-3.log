=== Command line arguments ===
Namespace(debug=False, batch_size=100, seed=3, precision=4, edgeitems=3, density=0.01, sizes='3072,32768,32768,32768,10', epochs=1, lr=0.1, momentum=0.9, gamma=0.1, nesterov=True, datadir='./data', augmented=False, preprocessed=None, copy=False, nerva=False, torch=True, scheduler='multistep', export_weights_npz=None, import_weights_npz=None, custom_masking=False)
Setting gamma to 1.0
Files already downloaded and verified
initialize by ER
Overall sparsity 0.01
Total Model parameters: 2248474624
Total parameters under sparsity level of 0.01: 0.009999760175189774
initialize by ER
Overall sparsity 0.01
Total Model parameters: 4496949248
Total parameters under sparsity level of 0.01: 0.00030868171363449643

=== PyTorch model ===
MLP1(
  (layers): ModuleList(
    (0): Linear(in_features=3072, out_features=32768, bias=True)
    (1): Linear(in_features=32768, out_features=32768, bias=True)
    (2): Linear(in_features=32768, out_features=32768, bias=True)
    (3): Linear(in_features=32768, out_features=10, bias=True)
  )
  (loss): CrossEntropyLoss()
)
CrossEntropyLoss()
<torch.optim.lr_scheduler.MultiStepLR object at 0x7f831dca4700>

=== Training PyTorch model ===
